import streamlit as st
from openai import OpenAI
import os
import time
import pandas as pd
from datetime import datetime
import plotly.express as px

# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="NEXUS - Assistente de IA Acad√™mico",
    page_icon="üß†",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Estilos CSS personalizados
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #4527A0;
        text-align: center;
        margin-bottom: 1rem;
    }
    .sub-header {
        font-size: 1.2rem;
        color: #5E35B1;
        text-align: center;
        margin-bottom: 2rem;
    }
    .chat-container {
        border-radius: 10px;
        background-color: #F5F5F5;
        padding: 20px;
        margin-bottom: 20px;
    }
    .user-message {
        background-color: #E3F2FD;
        padding: 10px;
        border-radius: 8px;
        margin: 10px 0;
        border-left: 5px solid #2196F3;
    }
    .assistant-message {
        background-color: #E8F5E9;
        padding: 10px;
        border-radius: 8px;
        margin: 10px 0;
        border-left: 5px solid #4CAF50;
    }
    .sidebar-content {
        padding: 20px 10px;
    }
    .metric-card {
        background-color: #FAFAFA;
        border-radius: 8px;
        padding: 15px;
        margin: 10px 0;
        box-shadow: 0 2px 5px rgba(0,0,0,0.1);
    }
</style>
""", unsafe_allow_html=True)

# Inicializa√ß√£o da sess√£o
if 'client' not in st.session_state:
    st.session_state.client = None
if 'messages' not in st.session_state:
    st.session_state.messages = []
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []
if 'token_usage' not in st.session_state:
    st.session_state.token_usage = {'prompt_tokens': 0, 'completion_tokens': 0}
if 'conversation_count' not in st.session_state:
    st.session_state.conversation_count = 0
if 'feedback_data' not in st.session_state:
    st.session_state.feedback_data = []
if 'api_key_configured' not in st.session_state:
    st.session_state.api_key_configured = False

# Sidebar para configura√ß√£o
with st.sidebar:
    st.markdown('<div class="sidebar-content">', unsafe_allow_html=True)
    st.image("https://via.placeholder.com/150x150.png?text=NEXUS", width=150)
    st.markdown("## Configura√ß√µes")
    
    # API Key Input
    api_key = st.text_input("OpenAI API Key", type="password", help="Insira sua chave de API da OpenAI")
    
    if api_key:
        try:
            st.session_state.client = OpenAI(api_key=api_key)
            if not st.session_state.api_key_configured:
                st.session_state.api_key_configured = True
                st.success("API configurada com sucesso!")
        except Exception as e:
            st.error(f"Erro ao configurar a API: {e}")
    
    # Configura√ß√µes do modelo
    st.markdown("### Modelo e Par√¢metros")
    model = st.selectbox("Modelo", ["gpt-3.5-turbo", "gpt-4o", "gpt-4"])
    temperature = st.slider("Temperatura", 0.0, 1.0, 0.7, 0.1)
    
    # Exibir m√©tricas
    st.markdown("### M√©tricas")
    col1, col2 = st.columns(2)
    with col1:
        st.markdown('<div class="metric-card">', unsafe_allow_html=True)
        st.metric("Conversas", st.session_state.conversation_count)
        st.markdown('</div>', unsafe_allow_html=True)
    with col2:
        st.markdown('<div class="metric-card">', unsafe_allow_html=True)
        st.metric("Tokens Usados", st.session_state.token_usage['prompt_tokens'] + st.session_state.token_usage['completion_tokens'])
        st.markdown('</div>', unsafe_allow_html=True)
    
    # Bot√£o para limpar o chat
    if st.button("Novo Chat"):
        st.session_state.messages = []
        st.session_state.conversation_count += 1
    
    # Bot√£o para exportar hist√≥rico
    if st.button("Exportar Hist√≥rico"):
        if st.session_state.chat_history:
            df = pd.DataFrame(st.session_state.chat_history)
            csv = df.to_csv(index=False).encode('utf-8')
            st.download_button(
                "Baixar CSV",
                csv,
                f"nexus_chat_history_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                "text/csv",
                key='download-csv'
            )
        else:
            st.warning("Nenhum hist√≥rico dispon√≠vel para exportar.")
    
    # Feedback
    st.markdown("### Feedback")
    feedback = st.radio("Como est√° sua experi√™ncia?", ["üòÄ Excelente", "üôÇ Boa", "üòê Neutra", "üôÅ Ruim", "üòû P√©ssima"])
    feedback_text = st.text_area("Coment√°rios adicionais")
    
    if st.button("Enviar Feedback"):
        st.session_state.feedback_data.append({
            'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            'rating': feedback,
            'comments': feedback_text
        })
        st.success("Feedback enviado. Obrigado!")
    
    st.markdown("</div>", unsafe_allow_html=True)

# Fun√ß√£o para gerar resposta
def generate_response(prompt, model, temperature):
    if not st.session_state.client:
        return "Por favor, configure sua API key na barra lateral."
    
    try:
        messages = [{"role": m["role"], "content": m["content"]} for m in st.session_state.messages]
        
        with st.spinner("NEXUS est√° processando..."):
            response = st.session_state.client.chat.completions.create(
                model=model,
                messages=messages,
                temperature=temperature
            )
        
        # Atualizar uso de tokens
        st.session_state.token_usage['prompt_tokens'] += response.usage.prompt_tokens
        st.session_state.token_usage['completion_tokens'] += response.usage.completion_tokens
        
        # Adicionar √† base de dados para an√°lise
        st.session_state.chat_history.append({
            'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            'user_message': prompt,
            'assistant_message': response.choices[0].message.content,
            'model': model,
            'temperature': temperature,
            'prompt_tokens': response.usage.prompt_tokens,
            'completion_tokens': response.usage.completion_tokens
        })
        
        return response.choices[0].message.content
    
    except Exception as e:
        return f"Erro ao gerar resposta: {str(e)}"

# Sistema de instru√ß√µes personalizado para o NEXUS
nexus_instructions = """
Voc√™ √© NEXUS, um assistente de IA especializado para pesquisadores e acad√™micos. Sua fun√ß√£o √© auxiliar em todas as etapas do trabalho acad√™mico, desde a concep√ß√£o de ideias at√© a publica√ß√£o.

Compet√™ncias:
1. Formula√ß√£o de perguntas de pesquisa e hip√≥teses
2. Sugest√£o de m√©todos e abordagens metodol√≥gicas
3. Revis√£o de literatura e recomenda√ß√£o de fontes
4. An√°lise cr√≠tica de argumentos e resultados
5. Sugest√£o de estruturas para artigos e apresenta√ß√µes
6. Formata√ß√£o e verifica√ß√£o de refer√™ncias bibliogr√°ficas
7. Explica√ß√£o de conceitos complexos de forma acess√≠vel

Ao responder:
- Forne√ßa informa√ß√µes precisas e baseadas em evid√™ncias
- Quando relevante, indique limita√ß√µes do seu conhecimento
- Ofere√ßa perspectivas diversas sobre t√≥picos controversos
- Use linguagem t√©cnica apropriada √† √°rea do conhecimento
- Priorize recursos e m√©todos recentes e bem estabelecidos

Voc√™ √© um assistente amig√°vel, respeitoso e √∫til, focado em potencializar o trabalho acad√™mico de alta qualidade.
"""

# Carregar mensagem de sistema
if len(st.session_state.messages) == 0:
    st.session_state.messages.append({"role": "system", "content": nexus_instructions})

# Interface principal
st.markdown('<h1 class="main-header">NEXUS</h1>', unsafe_allow_html=True)
st.markdown('<p class="sub-header">Assistente de IA Especializado para Pesquisadores e Acad√™micos</p>', unsafe_allow_html=True)

# √Årea de chat
st.markdown('<div class="chat-container">', unsafe_allow_html=True)
for message in st.session_state.messages:
    if message["role"] != "system":  # N√£o mostrar mensagens do sistema
        if message["role"] == "user":
            st.markdown(f'<div class="user-message">üë§ <b>Voc√™:</b> {message["content"]}</div>', unsafe_allow_html=True)
        else:
            st.markdown(f'<div class="assistant-message">üß† <b>NEXUS:</b> {message["content"]}</div>', unsafe_allow_html=True)
st.markdown('</div>', unsafe_allow_html=True)

# Input do usu√°rio
prompt = st.text_area("Digite sua pergunta ou instru√ß√£o para o NEXUS:", key="input")

# Verificar se o usu√°rio digitou algo
if st.button("Enviar") and prompt:
    # Adicionar mensagem do usu√°rio ao hist√≥rico
    st.session_state.messages.append({"role": "user", "content": prompt})
    # Exibir imediatamente a mensagem do usu√°rio
    st.markdown(f'<div class="user-message">üë§ <b>Voc√™:</b> {prompt}</div>', unsafe_allow_html=True)
    
    # Gerar resposta
    if st.session_state.api_key_configured:
        response = generate_response(prompt, model, temperature)
        # Adicionar resposta ao hist√≥rico
        st.session_state.messages.append({"role": "assistant", "content": response})
        # Exibir resposta do assistente
        st.markdown(f'<div class="assistant-message">üß† <b>NEXUS:</b> {response}</div>', unsafe_allow_html=True)
    else:
        st.warning("Por favor, configure sua API key da OpenAI na barra lateral para continuar.")
    
    # Recarregar para limpar o input
    st.experimental_rerun()

# Dashboard para an√°lise de uso (aba alternativa)
tab1, tab2 = st.tabs(["Chat", "An√°lise de Uso"])

with tab2:
    st.markdown("## An√°lise de Uso do NEXUS")
    
    if st.session_state.chat_history:
        # Converter hist√≥rico para DataFrame
        history_df = pd.DataFrame(st.session_state.chat_history)
        
        # Mostrar estat√≠sticas gerais
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Total de Intera√ß√µes", len(history_df))
        with col2:
            st.metric("Tokens Prompt", st.session_state.token_usage['prompt_tokens'])
        with col3:
            st.metric("Tokens Completion", st.session_state.token_usage['completion_tokens'])
        
        # Gr√°fico de tokens por conversa
        if len(history_df) > 1:
            history_df['total_tokens'] = history_df['prompt_tokens'] + history_df['completion_tokens']
            history_df['interaction_number'] = range(1, len(history_df) + 1)
            
            fig = px.line(history_df, x='interaction_number', y='total_tokens', 
                          title='Uso de Tokens por Intera√ß√£o')
            st.plotly_chart(fig, use_container_width=True)
        
        # Mostrar hist√≥rico recente
        st.markdown("### Hist√≥rico Recente")
        st.dataframe(
            history_df[['timestamp', 'user_message', 'assistant_message', 'model', 'total_tokens']]
            .sort_values('timestamp', ascending=False)
            .head(5)
        )
    else:
        st.info("Nenhum dado de uso dispon√≠vel ainda. Comece a conversar com o NEXUS para gerar estat√≠sticas.")

# Rodap√© com cr√©ditos
st.markdown("""
---
<div style="text-align: center; color: gray; font-size: 0.8rem;">
    NEXUS - Assistente de IA Acad√™mico | Desenvolvido com Streamlit e OpenAI
</div>
""", unsafe_allow_html=True)
